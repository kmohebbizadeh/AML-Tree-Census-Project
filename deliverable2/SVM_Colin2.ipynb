{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af5ed54",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "From Kiyan\n",
    "\n",
    "Hey everyone, just pushed a preprocessing script.\n",
    "you guys can decide what to use for the particular models, but there is a stratified dev and test set. for those that want to use the imbalanced sampling sets, I sampled the training set NOT THE DEV SET. I would reccomed to try to use train, val and test for all the models instead of just the dev and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda5cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0604404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data with relative path\n",
    "tree_df = pd.read_csv('2015_Street_Tree_Census_-_Tree_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9ac857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "tree_df = tree_df.drop(columns=[\n",
    "    'borocode', 'x_sp', 'y_sp', 'state', 'nta_name', 'zip_city', 'address',\n",
    "    'spc_latin', 'created_at', 'tree_id', 'block_id', 'user_type', 'bin',\n",
    "    'bbl', 'council district', 'boro_ct', 'census tract', 'problems', 'status',\n",
    "    'stump_diam', 'postcode', 'community board', 'cncldist', 'st_assem', 'st_senate', \n",
    "    'nta', 'spc_common'\n",
    "])\n",
    "\n",
    "# drop NA and dead tree values\n",
    "tree_df = tree_df[tree_df['health'].notna()]\n",
    "tree_df = tree_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d006d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale diameters \n",
    "scaler = StandardScaler()\n",
    "tree_df['tree_dbh'] = scaler.fit_transform(tree_df[['tree_dbh']])\n",
    "\n",
    "# Ordinal Encode\n",
    "health = ['Poor', 'Fair', 'Good']\n",
    "enc = OrdinalEncoder(categories=[health])\n",
    "tree_df['health'] = enc.fit_transform(tree_df[['health']])\n",
    "\n",
    "steward = ['None', '1or2', '3or4', '4orMore']\n",
    "enc = OrdinalEncoder(categories=[steward])\n",
    "tree_df['steward'] = enc.fit_transform(tree_df[['steward']])\n",
    "\n",
    "sidewalk = ['NoDamage', 'Damage']\n",
    "enc = OrdinalEncoder(categories=[sidewalk])\n",
    "tree_df['sidewalk'] = enc.fit_transform(tree_df[['sidewalk']])\n",
    "\n",
    "curbloc = ['OnCurb', 'OffsetFromCurb']\n",
    "enc = OrdinalEncoder(categories=[curbloc])\n",
    "tree_df['curb_loc'] = enc.fit_transform(tree_df[['curb_loc']])\n",
    "\n",
    "yes_no = ['No', 'Yes']\n",
    "enc = OrdinalEncoder(categories=[yes_no])\n",
    "\n",
    "yes_no_features = [\n",
    "    'brch_other', 'brch_shoe', 'brch_light', 'trnk_other', 'trnk_light',\n",
    "    'trunk_wire', 'root_other', 'root_grate', 'root_stone'\n",
    "]\n",
    "\n",
    "for feat in yes_no_features:\n",
    "    tree_df[feat] = enc.fit_transform(tree_df[[feat]])\n",
    "    \n",
    "# One Hot Encode\n",
    "enc = OneHotEncoder()\n",
    "guards = enc.fit_transform(tree_df[['guards']])\n",
    "tree_df['guards_' + enc.categories_[0][:]] = guards.toarray()\n",
    "tree_df = tree_df.drop(columns=['guards'])\n",
    "\n",
    "guards = enc.fit_transform(tree_df[['borough']])\n",
    "tree_df['borough_' + enc.categories_[0][:]] = guards.toarray()\n",
    "tree_df = tree_df.drop(columns=['borough'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5a8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to x and y sets\n",
    "y = np.asarray(tree_df['health'])\n",
    "x = tree_df.drop(columns=['health'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9769c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample (stratified) for dev, test, train and val\n",
    "x_dev, x_test, y_dev, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify = y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_dev, y_dev, test_size=0.2, random_state=42, stratify = y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb41879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# over-sampling of training data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feaa99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# under sampling of training data\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "x_rus, y_rus = rus.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dd33594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote sampling of training data\n",
    "smote = SMOTE(random_state=42)\n",
    "x_smote, y_smote = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11ed34",
   "metadata": {},
   "source": [
    "# Model: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5218d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, make_scorer, roc_auc_score, classification_report\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import seaborn as sns\n",
    "\"\"\"\n",
    "A short cut to print the svm model result.\n",
    "    Args:\n",
    "        svm: the svm model.\n",
    "        X_train: training data of X.\n",
    "        y_train: training data of y.\n",
    "        X_test: testing data of X.   \n",
    "        y_test: testing data of y.\n",
    "        report: boolean; print the classification report if true, default as \"True\".\n",
    "        cf: boolean; print the confusion matrix if true, default as \"True\".\n",
    "    Returns:\n",
    "        Print the training and the testing accuracy.\n",
    "        Return the classification report if report = True.\n",
    "        Return the confusion matrix if report = True.\n",
    "\"\"\"\n",
    "def SVM_result(svm, X_train, y_train, X_test, y_test, report_test = True, report_train = False, cf = False):\n",
    "    # fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    # predict y\n",
    "    y_train_predict = svm.predict(X_train)\n",
    "    y_test_predict = svm.predict(X_test)    \n",
    "    # show result report on testing data\n",
    "    if (report_test):\n",
    "        print(\"Result on test data:\")\n",
    "        print(classification_report(y_test, y_test_predict))\n",
    "    # show result report on training data\n",
    "    if (report_train):\n",
    "        print(\"Result on training data:\")\n",
    "        print(classification_report(y_train, y_train_predict))\n",
    "    # show confusion_matrix\n",
    "    if (cf):\n",
    "        cf = confusion_matrix(y_test, y_test_predict)\n",
    "        sns.heatmap(cf, annot = True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d1794",
   "metadata": {},
   "source": [
    "## Modeling and hyperparameter tuning for different sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e133925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV \n",
    "\n",
    "# Basic SVM models\n",
    "warnings.filterwarnings('ignore')\n",
    "# primal svm (for large data set) before hyperparameter tuning\n",
    "svm = LinearSVC(tol=0.0001, dual = False, random_state = 2022) \n",
    "# random search for hyperparameter tuning\n",
    "param_list = {'C': stats.uniform(0, 5), \n",
    "              'loss': ['hinge', 'squared_hinge']} # random list for hyperparameter tuning \n",
    "rand_search_ac = RandomizedSearchCV(svm, \n",
    "                                    param_distributions = param_list, \n",
    "                                    cv = 5,\n",
    "                                    scoring = 'accuracy',\n",
    "                                    random_state = 2022) \n",
    "\n",
    "rand_search_f1 = RandomizedSearchCV(svm, \n",
    "                                    param_distributions = param_list, \n",
    "                                    cv = 5,\n",
    "                                    scoring = 'f1_macro',\n",
    "                                    random_state = 2022) \n",
    "\n",
    "rand_search_recall = RandomizedSearchCV(svm, \n",
    "                                        param_distributions = param_list, \n",
    "                                        cv = 5,\n",
    "                                        scoring = 'recall_macro',\n",
    "                                        random_state = 2022) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b644bb20",
   "metadata": {},
   "source": [
    "### SVM for original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72946347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for tuning on accuray: {'C': 4.620282385385153, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      5363\n",
      "         1.0       0.35      0.01      0.02     19301\n",
      "         2.0       0.81      1.00      0.90    105770\n",
      "\n",
      "    accuracy                           0.81    130434\n",
      "   macro avg       0.39      0.34      0.31    130434\n",
      "weighted avg       0.71      0.81      0.73    130434\n",
      "\n",
      "Best parameters for tuning on f1: {'C': 4.620282385385153, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      5363\n",
      "         1.0       0.35      0.01      0.02     19301\n",
      "         2.0       0.81      1.00      0.90    105770\n",
      "\n",
      "    accuracy                           0.81    130434\n",
      "   macro avg       0.39      0.34      0.31    130434\n",
      "weighted avg       0.71      0.81      0.73    130434\n",
      "\n",
      "Best parameters for tuning on macro recall: {'C': 4.620282385385153, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      5363\n",
      "         1.0       0.35      0.01      0.02     19301\n",
      "         2.0       0.81      1.00      0.90    105770\n",
      "\n",
      "    accuracy                           0.81    130434\n",
      "   macro avg       0.39      0.34      0.31    130434\n",
      "weighted avg       0.71      0.81      0.73    130434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning random Sampling\n",
    "\n",
    "# accuracy as scoring metric\n",
    "rand_search_ac.fit(x_train, y_train)\n",
    "print(f\"Best parameters for tuning on accuray: {rand_search_ac.best_params_}\")\n",
    "SVM_result(rand_search_ac.best_estimator_, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# f1 as scoring metric\n",
    "rand_search_f1.fit(x_train, y_train) \n",
    "print(f\"Best parameters for tuning on f1: {rand_search_f1.best_params_}\")\n",
    "SVM_result(rand_search_f1.best_estimator_, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# macro-recall as scoring metric\n",
    "rand_search_recall.fit(x_train, y_train) \n",
    "print(f\"Best parameters for tuning on macro recall: {rand_search_recall.best_params_}\")\n",
    "SVM_result(rand_search_recall.best_estimator_, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70cbed3",
   "metadata": {},
   "source": [
    "### SVM after undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38694eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for tuning on accuray: {'C': 0.04679306903882352, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.53      0.12      5363\n",
      "         1.0       0.18      0.16      0.17     19301\n",
      "         2.0       0.85      0.56      0.68    105770\n",
      "\n",
      "    accuracy                           0.50    130434\n",
      "   macro avg       0.36      0.42      0.32    130434\n",
      "weighted avg       0.72      0.50      0.58    130434\n",
      "\n",
      "Best parameters for tuning on f1: {'C': 0.04679306903882352, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.53      0.12      5363\n",
      "         1.0       0.18      0.16      0.17     19301\n",
      "         2.0       0.85      0.56      0.68    105770\n",
      "\n",
      "    accuracy                           0.50    130434\n",
      "   macro avg       0.36      0.42      0.32    130434\n",
      "weighted avg       0.72      0.50      0.58    130434\n",
      "\n",
      "Best parameters for tuning on macro recall: {'C': 0.04679306903882352, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.53      0.12      5363\n",
      "         1.0       0.18      0.16      0.17     19301\n",
      "         2.0       0.85      0.56      0.68    105770\n",
      "\n",
      "    accuracy                           0.50    130434\n",
      "   macro avg       0.36      0.42      0.32    130434\n",
      "weighted avg       0.72      0.50      0.58    130434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning under sampling\n",
    "\n",
    "# accuracy as scoring metric\n",
    "rand_search_ac.fit(x_rus, y_rus)\n",
    "print(f\"Best parameters for tuning on accuray: {rand_search_ac.best_params_}\")\n",
    "SVM_result(rand_search_ac.best_estimator_, x_rus, y_rus, x_test, y_test)\n",
    "\n",
    "# f1 as scoring metric\n",
    "rand_search_f1.fit(x_rus, y_rus) \n",
    "print(f\"Best parameters for tuning on f1: {rand_search_f1.best_params_}\")\n",
    "SVM_result(rand_search_f1.best_estimator_, x_rus, y_rus, x_test, y_test)\n",
    "\n",
    "# macro-recall as scoring metric\n",
    "rand_search_recall.fit(x_rus, y_rus) \n",
    "print(f\"Best parameters for tuning on macro recall: {rand_search_recall.best_params_}\")\n",
    "SVM_result(rand_search_recall.best_estimator_, x_rus, y_rus, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12c2c5",
   "metadata": {},
   "source": [
    "### SVM after oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3da3574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for tuning on accuray: {'C': 4.620282385385153, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.53      0.12      5363\n",
      "         1.0       0.18      0.15      0.16     19301\n",
      "         2.0       0.85      0.57      0.68    105770\n",
      "\n",
      "    accuracy                           0.51    130434\n",
      "   macro avg       0.37      0.42      0.32    130434\n",
      "weighted avg       0.72      0.51      0.58    130434\n",
      "\n",
      "Best parameters for tuning on f1: {'C': 2.5660378900685785, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.53      0.12      5363\n",
      "         1.0       0.18      0.15      0.16     19301\n",
      "         2.0       0.85      0.57      0.68    105770\n",
      "\n",
      "    accuracy                           0.51    130434\n",
      "   macro avg       0.37      0.42      0.32    130434\n",
      "weighted avg       0.72      0.51      0.58    130434\n",
      "\n",
      "Best parameters for tuning on macro recall: {'C': 4.620282385385153, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.53      0.12      5363\n",
      "         1.0       0.18      0.15      0.16     19301\n",
      "         2.0       0.85      0.57      0.68    105770\n",
      "\n",
      "    accuracy                           0.51    130434\n",
      "   macro avg       0.37      0.42      0.32    130434\n",
      "weighted avg       0.72      0.51      0.58    130434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning over sampling\n",
    "\n",
    "# accuracy as scoring metric\n",
    "rand_search_ac.fit(x_ros, y_ros)\n",
    "print(f\"Best parameters for tuning on accuray: {rand_search_ac.best_params_}\")\n",
    "SVM_result(rand_search_ac.best_estimator_, x_ros, y_ros, x_test, y_test)\n",
    "\n",
    "# f1 as scoring metric\n",
    "rand_search_f1.fit(x_ros, y_ros) \n",
    "print(f\"Best parameters for tuning on f1: {rand_search_f1.best_params_}\")\n",
    "SVM_result(rand_search_f1.best_estimator_, x_ros, y_ros, x_test, y_test)\n",
    "\n",
    "# macro-recall as scoring metric\n",
    "rand_search_recall.fit(x_ros, y_ros) \n",
    "print(f\"Best parameters for tuning on macro recall: {rand_search_recall.best_params_}\")\n",
    "SVM_result(rand_search_recall.best_estimator_, x_ros, y_ros, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88bb305",
   "metadata": {},
   "source": [
    "### SVM after smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "229dfc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for tuning on accuray: {'C': 0.04679306903882352, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.06      0.54      0.12      5363\n",
      "         1.0       0.18      0.16      0.17     19301\n",
      "         2.0       0.85      0.56      0.67    105770\n",
      "\n",
      "    accuracy                           0.50    130434\n",
      "   macro avg       0.37      0.42      0.32    130434\n",
      "weighted avg       0.72      0.50      0.58    130434\n",
      "\n",
      "Best parameters for tuning on f1: {'C': 1.5080409805315753, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.06      0.54      0.12      5363\n",
      "         1.0       0.18      0.16      0.17     19301\n",
      "         2.0       0.85      0.56      0.67    105770\n",
      "\n",
      "    accuracy                           0.50    130434\n",
      "   macro avg       0.37      0.42      0.32    130434\n",
      "weighted avg       0.72      0.50      0.58    130434\n",
      "\n",
      "Best parameters for tuning on macro recall: {'C': 0.04679306903882352, 'loss': 'squared_hinge'}\n",
      "Result on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.06      0.54      0.12      5363\n",
      "         1.0       0.18      0.16      0.17     19301\n",
      "         2.0       0.85      0.56      0.67    105770\n",
      "\n",
      "    accuracy                           0.50    130434\n",
      "   macro avg       0.37      0.42      0.32    130434\n",
      "weighted avg       0.72      0.50      0.58    130434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning after smote sampling\n",
    "\n",
    "# accuracy as scoring metric\n",
    "rand_search_ac.fit(x_smote, y_smote)\n",
    "print(f\"Best parameters for tuning on accuray: {rand_search_ac.best_params_}\")\n",
    "SVM_result(rand_search_ac.best_estimator_, x_smote, y_smote, x_test, y_test)\n",
    "\n",
    "# f1 as scoring metric\n",
    "rand_search_f1.fit(x_smote, y_smote) \n",
    "print(f\"Best parameters for tuning on f1: {rand_search_f1.best_params_}\")\n",
    "SVM_result(rand_search_f1.best_estimator_, x_smote, y_smote, x_test, y_test)\n",
    "\n",
    "# macro-recall as scoring metric\n",
    "rand_search_recall.fit(x_smote, y_smote) \n",
    "print(f\"Best parameters for tuning on macro recall: {rand_search_recall.best_params_}\")\n",
    "SVM_result(rand_search_recall.best_estimator_, x_smote, y_smote, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
